#! /usr/bin/env ruby

# frozen_string_literal: true

LKP_SRC = ENV['LKP_SRC'] || File.dirname(File.dirname(File.realpath($PROGRAM_NAME)))

require "#{LKP_SRC}/lib/job2sh"
require "#{LKP_SRC}/lib/distro_info"
require "#{LKP_SRC}/lib/scheduler_client"
require 'optparse'
require 'yaml'

opt_set_key_value = {}
opt_output_dir = nil
opt_auto_define_files = false
opt_monitor = false
opt_monitor_query = {}
opt_auto_connect = false

options = OptionParser.new do |opts|
  opts.banner = 'Usage: submit [options] jobs...'

  opts.separator '       submit test jobs to the scheduler'
  opts.separator ''
  opts.separator 'options:'

  opts.on("-s 'KEY: VALUE'", "--set 'KEY: VALUE'", 'add YAML hash to job') do |key_value|
    opt_set_key_value.merge! YAML.load key_value
  end

  opts.on('-o DIR', '--output DIR', 'save job yaml to DIR/') do |dir|
    if File.file? dir
      puts "Please input directory for job save yaml after '-o'"
      exit 1
    end
    opt_output_dir = dir
    Dir.mkdir(dir) unless File.directory? dir
  end

  opts.on('-a', '--auto-define-files', 'auto add define_files') do
    opt_auto_define_files = true
  end

  opts.on('-c', '--connect', 'auto connect to the host') do
    opt_auto_connect = true
  end

  opts.on('-m', '--monitor', "monitor job status: use -m 'KEY: VALUE' to add rule") do
    opt_monitor = true
    filter = YAML.load ARGV[0] if ARGV[0]
    if filter.class == Hash
      opt_monitor_query.merge! filter
      ARGV.shift
    end
  end
end

options.parse!(ARGV)

ARGV.delete_if do |arg|
  if arg.index '='
    opt_set_key_value.merge! YAML.load arg.sub(/=/, ': ')
    true
  else
    false
  end
end

if ARGV.size.zero?
  puts(options)
  exit
end

job_ids = []

ARGV.each do |jobfile|
  jobs = Job2sh.new
  jobs.overrides = opt_set_key_value
  jobs.load(jobfile, true) || next
  jobs[:expand_params] = true
  jobs['testbox'] = opt_set_key_value['testbox'] if opt_set_key_value['testbox']
  jobs['tbox_group'] = tbox_group(jobs['testbox']) if jobs.include?('testbox')
  jobs['node_roles'] ||= 'server client' if jobs['cluster']
  jobs.each_jobs do |job|
    raise 'Please configure SCHED_HOST' unless job['SCHED_HOST']
    raise 'Please configure SCHED_PORT' unless job['SCHED_PORT']

    job['LKP_CGI_PORT'] = job['SCHED_PORT']
    job['LKP_SERVER'] = job['SCHED_HOST']

    job.add_pp
    job.add_define_files if opt_auto_define_files

    # get job shell function
    sh_run_job = job.sh_run_job
    sh_extract_stats = job.sh_extract_stats
    sh_define_files = job.sh_define_files

    sh_hash = {
      'job2sh' => {
        'run_job' => sh_run_job,
        'extract_stats' => sh_extract_stats,
        'define_files' => sh_define_files
      }
    }

    # merge job info
    job_hash = job.to_hash
    job_hash = job_hash.merge(sh_hash)

    # save job to yaml
    if opt_output_dir
      prefix = File.join(opt_output_dir, File.basename(jobfile, '.yaml'))
      unit_jobfile = prefix + '-' + job.path_params + '.yaml'
      job.save unit_jobfile
      puts "#{jobfile} => #{unit_jobfile}"
      next
    end

    # init scheduler client
    scheduler_client = SchedulerClient.new(job['SCHED_HOST'], job['SCHED_PORT'])

    # submit job
    job_json = job_hash.to_json
    messages = scheduler_client.submit_job(job_json)
    JSON.parse(messages).each do |msg|
      if msg['message'].empty?
        job_ids << msg['job_id'].to_s
        puts("submit #{jobfile}, got job_id=#{msg['job_id']}")
      else
        puts("submit #{jobfile} failed, got job_id=#{msg['job_id']}, error: #{msg['message']}")
      end
    end
  end
end

if opt_monitor
  opt_monitor_query.merge!({'job_id' => job_ids[0]})
  cmd = "#{LKP_SRC}/sbin/monitor -f \'#{opt_monitor_query.to_json}\'"
  cmd += ' -t connect' if opt_auto_connect
  exec cmd
end
