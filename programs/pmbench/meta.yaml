metadata:
  name: pmbench
  summary: pmbench - paging and virtual memory benchmark
  description: |-
    pmbench is a micro-benchmark that profiles system paging performance by
    measuring latencies of  each  memory  access  throughout  the  run  and
    reporting the statistics of measured latencies.
  homepage:
type: workload
depends:
  debian@11:
  - uuid-dev
  - libxml2-dev
params:
  runtime:
  mapsize:
    doc: Specify virtual address map size in Mebibyte (2^20 bytes)  unit. The default
      is 256.
  setsize:
    doc: Specify  working  set  size  in  Mebibyte unit.  It should be no greater
      than mapsize. The default is 128.
  pattern:
    doc: "(linear, uniform, normal, pareto)"
  shape:
    doc: Pattern-specific  numeric parameter that determines the shape of the distribution.  See
      Usage for details.
  jobs:
    doc: Number of concurrent worker threads to spawn for the  benchmark. Some releases
      may not support this option. The default is 1.
  timestamp:
    doc: "(rdtsc, rdtscp, perfc)"
  cold:
    doc: "(y, n)"
  access:
    doc: "(histo, touch)"
  delay:
    doc: Delay between accesses in clock cycles
  initialize:
    doc: "(y, n) Initialize memory map with garbage data"
  offset:
    doc: Specify static page access offset (default random)
  quiet:
    doc: "(y, n) Don't produce any output until finish"
  ratio:
    doc: Percentage read/write ratio (0 = write only, 100 = read only; default 50)
  threshold:
    doc: The threshold time to trigger the ftrace log, unit is ns.
results:
  latency.ns.average:
  read.latency.ns.0-256%:
  read.latency.ns.256-512%:
  read.latency.ns.512-1K%:
  read.latency.ns.1K-2K%:
  read.latency.ns.2K-4K%:
  read.latency.ns.4K-8K%:
  read.latency.ns.8K-16K%:
  read.latency.ns.16K-32K%:
  read.latency.ns.32K-64K%:
  read.latency.ns.64K-128K%:
  read.latency.ns.128K-256K%:
  read.latency.ns.256K-512K%:
  read.latency.ns.512K-1M%:
  read.latency.ns.1M-2M%:
  read.latency.ns.2M-4M%:
  read.latency.ns.4M-8M%:
  read.latency.ns.8M-16M%:
  read.latency.ns.16M-32M%:
  read.latency.ns.32M-64M%:
  read.latency.ns.64M-128M%:
  read.latency.ns.128M-256M%:
  read.latency.ns.256M-512M%:
  read.latency.ns.512M-1G%:
  read.latency.ns.1G-inf%:
  write.latency.ns.0-256%:
  write.latency.ns.256-512%:
  write.latency.ns.512-1K%:
  write.latency.ns.1K-2K%:
  write.latency.ns.2K-4K%:
  write.latency.ns.4K-8K%:
  write.latency.ns.8K-16K%:
  write.latency.ns.16K-32K%:
  write.latency.ns.32K-64K%:
  write.latency.ns.64K-128K%:
  write.latency.ns.128K-256K%:
  write.latency.ns.256K-512K%:
  write.latency.ns.512K-1M%:
  write.latency.ns.1M-2M%:
  write.latency.ns.2M-4M%:
  write.latency.ns.4M-8M%:
  write.latency.ns.8M-16M%:
  write.latency.ns.16M-32M%:
  write.latency.ns.32M-64M%:
  write.latency.ns.64M-128M%:
  write.latency.ns.128M-256M%:
  write.latency.ns.256M-512M%:
  write.latency.ns.512M-1G%:
  write.latency.ns.1G-inf%:
